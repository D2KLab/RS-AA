{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import string \n",
    "import pickle\n",
    "import datetime\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint \n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_talks = pd.read_csv('../Data/talks_data.csv')\n",
    "\n",
    "df_talks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_talks['text'] =  df_talks['transcript'] + ' ' + df_talks['description'] + ' ' + df_talks['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = word_tokenize('hello darkness my old friend')\n",
    "l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "docs = [s.translate(str.maketrans('', '', string.punctuation)).split() for s in tqdm(df_talks.text)]\n",
    "docs = [[w.lower() for w in doc if w.lower() not in stop_words and len(w) > 3 and not w.endswith(':') and not w.endswith(')')] for doc in docs]\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counter = Counter([w for d in docs for w in d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_words = set([w[0] for w in word_counter.most_common(512)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_filtered = [[w for w in doc if w not in most_frequent_words] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_counter) * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(docs_filtered)\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in docs_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 40\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=num_topics, \n",
    "                                           random_state=42,\n",
    "                                           passes=50, # 30 is too good\n",
    "                                           alpha='auto',\n",
    "                                           eta='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for t in lda_model.show_topics(40, num_words=8):\n",
    "    print('Topic', t[0], end=': ')\n",
    "    for w in t[1].split(' + '):\n",
    "        print(w.split('*')[1], end=', ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_per_talk = lda_model.get_document_topics(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_per_talk[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_perc = 0.03\n",
    "\n",
    "with open('../kg_embeddings/metadata-interactions-tm/ted-tm-min'+str(cutoff_perc)+'_n'+str(num_topics)+'.txt', 'w') as f:\n",
    "\n",
    "    for i, talk in enumerate(df_talks['id'].values):\n",
    "        talk_topics = topic_per_talk[i]\n",
    "        for topic, perc in talk_topics:\n",
    "            if perc >= cutoff_perc:\n",
    "                f.write(f'{talk}\\thasTopic\\ttopic_{topic}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_perc = 0.3\n",
    "\n",
    "with open('../kg_embeddings/metadata-interactions-tm/ted-tm-min'+str(cutoff_perc)+'_n'+str(num_topics)+'.txt', 'w') as f:\n",
    "\n",
    "    for i, talk in enumerate(df_talks['id'].values):\n",
    "        talk_topics = topic_per_talk[i]\n",
    "        for topic, perc in talk_topics:\n",
    "            if perc >= cutoff_perc:\n",
    "                f.write(f'{talk}\\thasTopic\\ttopic_{topic}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cutoff in ['0.3', '0.03']:\n",
    "    ! cat ../kg_embeddings/metadata-interactions-tm/ted-all-data-test.txt ../kg_embeddings/metadata-interactions-tm/ted-tm-min{cutoff}_n{num_topics}.txt > ../kg_embeddings/metadata-interactions-tm/ted-all-tm-{cutoff}-test.txt\n",
    "    ! cat ../kg_embeddings/metadata-interactions-tm/ted-all-data-train.txt ../kg_embeddings/metadata-interactions-tm/ted-tm-min{cutoff}_n{num_topics}.txt > ../kg_embeddings/metadata-interactions-tm/ted-all-tm-{cutoff}-train.txt\n",
    "    ! cat ../kg_embeddings/metadata-interactions-tm/ted-all-data-valid.txt ../kg_embeddings/metadata-interactions-tm/ted-tm-min{cutoff}_n{num_topics}.txt > ../kg_embeddings/metadata-interactions-tm/ted-all-tm-{cutoff}-valid.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
